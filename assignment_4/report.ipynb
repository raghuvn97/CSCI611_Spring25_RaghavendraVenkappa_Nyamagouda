{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d69d8f1-93a9-4c66-b7df-be719576235d",
   "metadata": {},
   "source": [
    "# Report on Implementation and Findings of Style Transfer Exercise\n",
    "\n",
    "## 1. Introduction\n",
    "This report summarizes the implementation and findings of the style transfer. The objective was to apply neural style transfer techniques to modify the artistic appearance of an image while preserving its content structure. The Style transfer uses a convolutional neural network (CNN) to combine the content of one image with the artistic style of another, creating a visually appealing blended output.\n",
    "\n",
    "## 2. Implementation\n",
    "The style transfer was implemented using a deep learning-based approach, leveraging a pre-trained convolutional neural network (CNN). The key steps involved in the implementation include:\n",
    "\n",
    "- **Loading the Pre-trained Model**: A VGG-based architecture, specifically VGG-19, was used for feature extraction. The model was pre-trained on ImageNet, making it well-suited for extracting relevant style and content features.\n",
    "- **Extracting Features from Layers**: Specific layers in the VGG model were used to extract content and style representations.\n",
    "- **Defining Loss Functions**:\n",
    "  - **Content loss**: Measures the difference between the content image and the output image, ensuring that the original image structure is preserved.\n",
    "  - **Style loss**: Uses Gram matrices to compare the correlation of features between the style image and the generated image. It ensures that the texture and patterns from the style image are successfully transferred.\n",
    "  - **Total variation loss** (optional): Helps to reduce noise and enforce smoothness in the generated image.\n",
    "- **Optimization Process**:\n",
    "  - The generated image is initialized as a copy of the content image and iteratively updated using gradient descent.\n",
    "  - The Adam optimizer was employed to update pixel values based on the computed loss gradients.\n",
    "  - The output image is refined over multiple iterations to minimize the combined loss function.\n",
    "- **Hyperparameter Tuning**:\n",
    "  - The impact of different style and content weight ratios was analyzed.\n",
    "  - The choice of learning rate was carefully tuned to ensure stable convergence.\n",
    "\n",
    "## 3. Key Code Snippets\n",
    "\n",
    "### Loading VGG Model\n",
    "```python\n",
    "vgg = models.vgg19(pretrained=True).features.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982de5f6-010c-41a8-8de6-0bb42acf2b12",
   "metadata": {},
   "source": [
    "### Content Loss Calculation\n",
    "```python\n",
    "def content_loss(content_features, generated_features):\n",
    "    return torch.mean((content_features - generated_features) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862e196f-dbc5-4a07-85b0-8bf6b5ad7f09",
   "metadata": {},
   "source": [
    "### Style Loss Calculation\n",
    "```python\n",
    "def gram_matrix(tensor):\n",
    "    _, d, h, w = tensor.size()\n",
    "    tensor = tensor.view(d, h * w)\n",
    "    return torch.mm(tensor, tensor.t()) / (d * h * w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313b0a8c-2596-437f-bbd9-70d43aea57f3",
   "metadata": {},
   "source": [
    "### Optimization Setup\n",
    "```python\n",
    "optimizer = torch.optim.Adam([generated_image], lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d935c4f0-cfdb-403f-aecd-61f95d03c862",
   "metadata": {},
   "source": [
    "## 4. Findings and Analysis\n",
    "\n",
    "### Effect of Style Weight\n",
    "- Increasing the style weight resulted in more pronounced artistic transformations, capturing textures and patterns effectively\n",
    "- Excessive style weight led to loss of structural integrity, making the output less recognizable\n",
    "\n",
    "### Impact of Learning Rate\n",
    "- High learning rate caused instability\n",
    "- Lower learning rate produced smoother transitions but required more iterations\n",
    "\n",
    "### Effect of Iterations\n",
    "- More iterations → more refined style transfer\n",
    "- Excessive iterations → over-smoothed images with lost details\n",
    "\n",
    "### Visualization of Results\n",
    "- Successful blending of content structure with artistic style\n",
    "- Example transformations:\n",
    "  - Content Image → Processed Image\n",
    "  - Style Image → Processed Image\n",
    "- Key finding: Balance between content and style weight is crucial for aesthetic results\n",
    "\n",
    "## Conclusion and Future Work\n",
    "\n",
    "### Conclusion\n",
    "The implementation successfully demonstrated CNNs' ability to:\n",
    "- Blend artistic styles into content images\n",
    "- Preserve structural details while capturing artistic textures\n",
    "\n",
    "### Future Work Directions\n",
    " **Architecture Experiments**\n",
    "   - Transformer-based models for faster inference\n",
    "   - Comparison of different backbone networks\n",
    "**Performance Optimization**\n",
    "   - Real-time style transfer using lightweight models\n",
    "   - Quantization and pruning techniques\n",
    "\n",
    "**Advanced Style Blending**\n",
    "   - Multi-style simultaneous application\n",
    "   - Region-specific style control\n",
    "   - Dynamic style interpolation\n",
    "\n",
    "**Application Expansion**\n",
    "   - Video style transfer\n",
    "   - Interactive style adjustment\n",
    "   - Mobile deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fb5fb3-50c6-41c3-b30b-9c04fae2e4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
